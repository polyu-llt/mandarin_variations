Our model is based on SVM ensembles.

We created five parallel classifiers, each of them generated with different parameters: character-based bigrams, character-based trigrams, character-based 4-grams, character-based 5-grams and word-based unigrams. This combination was chosen through grid search.

All classifiers are based on LinearSVC from sklearn, which is a Support Vector Machine with a linear kernel. The penalty value C = 5.

All classifiers were calibrated with CalibratedClassifierCV, also from sklearn because the original SVM does not include a probability feature, and fitted by the union of the training set as well as the development set. 

After fitting the training data to the classifiers, we predict the labels of the testing set, from which we get four probability matrices generated by each of the classifiers. We then apply a fusion method which follows the mean probability rule to calculate the average probabilities of each label for each sentence, and pick the highest one as the final decision.

